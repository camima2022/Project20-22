
ResNet_BiGRU_Attention_4_class.py

8x9 2x16x(5,9)

structure:
no  block1  block2  max/ave    td_max/ td_ave
1 16x3   16x5   0.9986/0.9971    120/117
2 32x3   32x5   0.9990/0.9988    148/145
3 64x3   64x5   0.9987/0.9987      223/219
4 16x3   16x9   0.9991/0.9975      125/124
5 32x3   32x9    0.9991/0.9990     156/155
6 64x3   64x9    0.9991/0.9990       252/249
7 16x5   16x9   0.9989/0.9982   127/129
8 32x5   32x9   0.9991/9990     191/160
9 64x5   64x9   0.9991/0.9989       273/292

epoch = 30

No.4 16x3   16x9   0.9991     125
PreResNet_BiGRU_Attention:
Eval      	0	1	2	3
Precision 	0.9999	0.9982	0.9991	0.9992
Recall    	1.0	0.9995	0.9995	0.9955
F1        	1.0	0.9988	0.9993	0.9973
[0.9906, 0.9852, 0.9958, 0.9957, 0.9908, 0.9965, 0.9865, 0.9966, 0.9981, 0.998, 0.9981, 0.9985, 0.9972, 0.9971, 0.9984, 0.9957, 0.9978, 0.9986, 0.9987, 0.9986, 0.9978, 0.9983, 0.9986, 0.9988, 0.9985, 0.9978, 0.9988, 0.9986, 0.9991, 0.9962, 0.994, 0.9987, 0.7763, 0.9988, 0.9986, 0.9992, 0.9987, 0.9992, 0.9987, 0.9992]
[0.9716, 0.9944, 0.9961, 0.9963, 0.997, 0.9971, 0.9975, 0.9978, 0.998, 0.9981, 0.9982, 0.9984, 0.9984, 0.9983, 0.9986, 0.9985, 0.9986, 0.9986, 0.9987, 0.9987, 0.9988, 0.9988, 0.9988, 0.9988, 0.999, 0.9991, 0.999, 0.9991, 0.9991, 0.9989, 0.9991, 0.999, 0.9991, 0.9992, 0.9993, 0.9991, 0.9992, 0.9994, 0.9993, 0.9993]
[0.0931, 0.0258, 0.0196, 0.0179, 0.0136, 0.011, 0.0087, 0.0079, 0.0072, 0.0069, 0.0062, 0.0058, 0.0057, 0.0056, 0.0046, 0.0047, 0.0048, 0.0047, 0.0044, 0.0042, 0.0039, 0.0041, 0.0036, 0.0038, 0.0033, 0.0033, 0.0034, 0.0031, 0.0031, 0.0036, 0.003, 0.0033, 0.0029, 0.0026, 0.0025, 0.0033, 0.003, 0.0026, 0.0024, 0.0025]
[0.0393, 0.0462, 0.0278, 0.0181, 0.0294, 0.0104, 0.0356, 0.0144, 0.0067, 0.0076, 0.0066, 0.0059, 0.0068, 0.0076, 0.0068, 0.0077, 0.0108, 0.0049, 0.0085, 0.0072, 0.006, 0.0066, 0.0052, 0.0047, 0.0053, 0.0089, 0.0055, 0.005, 0.0034, 0.013, 0.0111, 0.0038, 1.1326, 0.0037, 0.0043, 0.0033, 0.0039, 0.0042, 0.0039, 0.0033]
from the reuslt of No.4 epoch=30 is the best choice

PreResNet_BiGRU:
0.9986   113s
Eval      	0	1	2	3
Precision 	0.9998	0.9964	0.999	0.9995
Recall    	1.0	0.9996	0.9988	0.9924
F1        	0.9999	0.998	0.9989	0.9959

LiDaoQuan:

0.9966   47
Eval      	0	1	2	3
Precision 	0.9996	0.9932	0.9967	0.9966
Recall    	0.9998	0.9994	0.9977	0.9825
F1        	0.9997	0.9963	0.9972	0.9895
[0.8914, 0.952, 0.9732, 0.9782, 0.9861, 0.9877, 0.9902, 0.9908, 0.9928, 0.9929, 0.9942, 0.9953, 0.9919, 0.9939, 0.9925, 0.9946, 0.9953, 0.9958, 0.9962, 0.9955, 0.9964, 0.9901, 0.9925, 0.9962, 0.9959, 0.9962, 0.9965, 0.9966, 0.995, 0.9964, 0.9968, 0.9967, 0.9963, 0.9966, 0.9965, 0.9967, 0.9943, 0.9954, 0.9964, 0.9965]
[0.7889, 0.9058, 0.9363, 0.955, 0.9668, 0.9753, 0.9791, 0.9817, 0.9831, 0.9854, 0.9863, 0.988, 0.9897, 0.9901, 0.9904, 0.9917, 0.9922, 0.992, 0.9928, 0.9935, 0.9931, 0.9923, 0.9942, 0.9943, 0.994, 0.9938, 0.9946, 0.9951, 0.9949, 0.995, 0.9945, 0.9953, 0.9954, 0.9953, 0.9954, 0.9955, 0.9951, 0.9948, 0.9956, 0.9962]
[0.5289, 0.2702, 0.1995, 0.1506, 0.1185, 0.0935, 0.0787, 0.0715, 0.0653, 0.0587, 0.0546, 0.0488, 0.043, 0.0423, 0.039, 0.0347, 0.0328, 0.034, 0.031, 0.0278, 0.0289, 0.0326, 0.0253, 0.0252, 0.0264, 0.0262, 0.0237, 0.0205, 0.0218, 0.022, 0.0227, 0.0201, 0.0193, 0.0202, 0.0192, 0.0194, 0.0209, 0.0213, 0.0182, 0.0163]
[0.269, 0.1538, 0.1112, 0.0895, 0.0569, 0.0464, 0.0381, 0.0347, 0.0297, 0.0292, 0.0231, 0.0217, 0.0281, 0.0228, 0.0256, 0.0216, 0.0201, 0.0188, 0.0169, 0.0199, 0.0172, 0.031, 0.0246, 0.0166, 0.0161, 0.0155, 0.0156, 0.0146, 0.0205, 0.0163, 0.0138, 0.0142, 0.0145, 0.0152, 0.0136, 0.0152, 0.0298, 0.0199, 0.0152, 0.0154]


MMN_CNN:
0.9953     30s

Eval      	0	1	2	3
Precision 	0.9996	0.9883	0.9964	0.9974
Recall    	0.9998	0.9994	0.9938	0.9815
F1        	0.9997	0.9938	0.9951	0.9894
[0.9317, 0.954, 0.9613, 0.9728, 0.9769, 0.9712, 0.9833, 0.9736, 0.9853, 0.9882, 0.9225, 0.9867, 0.9894, 0.9931, 0.9904, 0.9935, 0.9915, 0.9932, 0.9908, 0.9936, 0.9907, 0.9946, 0.9927, 0.9928, 0.9941, 0.9943, 0.9942, 0.9946, 0.9953, 0.9948, 0.9961, 0.9952, 0.9948, 0.9947, 0.994, 0.9953, 0.9959, 0.996, 0.9957, 0.9956]
[0.8578, 0.9521, 0.9602, 0.9657, 0.9712, 0.9749, 0.9773, 0.9814, 0.9837, 0.9847, 0.986, 0.9872, 0.9889, 0.9902, 0.991, 0.9919, 0.9923, 0.9928, 0.9928, 0.9936, 0.9937, 0.994, 0.9938, 0.9943, 0.9941, 0.9943, 0.9948, 0.995, 0.9949, 0.995, 0.9953, 0.9952, 0.9954, 0.9955, 0.9955, 0.9955, 0.9955, 0.9956, 0.9957, 0.9956]
[0.3922, 0.1611, 0.1358, 0.1194, 0.1049, 0.0959, 0.0884, 0.075, 0.0682, 0.064, 0.0608, 0.0565, 0.0505, 0.047, 0.0435, 0.0402, 0.0389, 0.0371, 0.036, 0.0334, 0.033, 0.0315, 0.032, 0.0302, 0.031, 0.0296, 0.0273, 0.0273, 0.0268, 0.0264, 0.0257, 0.0257, 0.0253, 0.0251, 0.024, 0.0241, 0.0236, 0.023, 0.0231, 0.0233]
[0.1965, 0.1428, 0.1432, 0.0999, 0.0919, 0.1026, 0.0739, 0.0916, 0.0634, 0.0531, 0.2212, 0.0553, 0.0479, 0.0402, 0.047, 0.0376, 0.0434, 0.0351, 0.0422, 0.0335, 0.0416, 0.0307, 0.0345, 0.0324, 0.0325, 0.0299, 0.0296, 0.0298, 0.0281, 0.0279, 0.0236, 0.0278, 0.0271, 0.0278, 0.029, 0.0245, 0.0236, 0.0227, 0.0227, 0.0237]

PrtCNN:
val_accuracy: 0.9970   41s
Eval      	0	1	2	3
Precision 	0.9998	0.996	0.9974	0.9922
Recall    	0.9998	0.9995	0.9954	0.9897
F1        	0.9998	0.9977	0.9964	0.991
[0.9485, 0.9633, 0.9808, 0.9487, 0.9877, 0.9904, 0.9863, 0.9698, 0.9928, 0.9924, 0.9904, 0.9911, 0.9943, 0.9915, 0.9938, 0.9894, 0.9952, 0.994, 0.9961, 0.9939, 0.9948, 0.9961, 0.9957, 0.9962, 0.9961, 0.997, 0.9965, 0.9957, 0.9963, 0.9966, 0.9967, 0.9948, 0.9975, 0.9954, 0.9971, 0.9973, 0.9972, 0.9978, 0.9972, 0.9971]
[0.8653, 0.9534, 0.9662, 0.9749, 0.9806, 0.984, 0.9862, 0.9875, 0.9889, 0.9892, 0.9897, 0.9905, 0.9916, 0.9921, 0.9923, 0.9938, 0.9939, 0.9945, 0.9948, 0.9952, 0.9954, 0.9959, 0.9963, 0.9961, 0.9967, 0.997, 0.997, 0.9973, 0.9972, 0.9972, 0.9976, 0.9973, 0.9976, 0.9976, 0.9979, 0.998, 0.9979, 0.9981, 0.9983, 0.9981]
[0.3359, 0.134, 0.1012, 0.0769, 0.0614, 0.0534, 0.0452, 0.0411, 0.0372, 0.0353, 0.0345, 0.0306, 0.0281, 0.0262, 0.026, 0.0211, 0.0207, 0.0184, 0.0175, 0.0167, 0.0159, 0.0141, 0.013, 0.013, 0.0114, 0.011, 0.0111, 0.0103, 0.0097, 0.0098, 0.0086, 0.0102, 0.0084, 0.0088, 0.0078, 0.007, 0.0076, 0.0066, 0.0062, 0.0069]
[0.1361, 0.1046, 0.067, 0.1219, 0.0448, 0.0342, 0.047, 0.0881, 0.0271, 0.0264, 0.0307, 0.027, 0.02, 0.0279, 0.0208, 0.0347, 0.017, 0.0217, 0.0154, 0.0199, 0.0173, 0.014, 0.0176, 0.0131, 0.0151, 0.0131, 0.0125, 0.0181, 0.0126, 0.0139, 0.0133, 0.0185, 0.0108, 0.0166, 0.0122, 0.0127, 0.0119, 0.0118, 0.0121, 0.0131]



